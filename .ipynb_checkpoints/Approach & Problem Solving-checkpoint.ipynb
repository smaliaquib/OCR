{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Approach & Problem Solving</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Recognition = Text detection + Recognition\n",
    "\n",
    "\n",
    "<h3>Step: 1 Resnet50(Text Detection)</h3>\n",
    "\n",
    "So what i did First for detecting the image i need to localize the image for that i have taken help from github EAST project which was used to localized the text from Resnet50 i learned the model how it works how it takes the input and what it gives the output and that geo_map and score_map get converted to 8 points with with 4 Rows and 2 Col then what i did i used that 8 points and cropped the text images by dividing it by original images from that so that it can be ready for my CRNN input\n",
    "\n",
    "<h3>Step 2: CRNN(Text Recognition)</h3>\n",
    "\n",
    "After the images got cropped by the model now it is ready to take the input i used CRNN(Convolutional + Recurrent Neural Network(Bidirectional LSTM)) with Transcript layer(CTC). convoultion layer to extracts features splitting the feature and input to the Bidirectional LSTM then Conversion of feature predictions to Label using Transcript layer (CTC).Firstly i trained the model in synthetic dataset consisting of alphabets and number arround 3 Lakh images were their i got the accuracy of 70% in that then i fine tuned the model with my own datasets due to lack of datasets i generated the vin number and license (800 vin + 800 license + cropped from registration card) and with the help of pillow library i drawn each vin number images with the respective names then i trained the images in that  \n",
    "\n",
    "<h3>(Text Detection) + (Text Recognition)</h3>\n",
    "\n",
    "After Building all the model i used one model to detect images from registration card and another to recognize the images.To detect names i used synth dataset weights to to detect the names from and to recognize the vin/license i used the fine tune weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Issues</h3>\n",
    "\n",
    "1. Need more data to detect the the vin number properly it can detect the names very accurately because it is trained in 3 lakh alphabet + numbers<br>\n",
    "2. Text detection model should be trained more to get more accurate because its a base model if it detect accurate the ouput will be also accurate<br>\n",
    "3. I trained all models in google collab due to lack of specs in my lappy i have trained in google collab and session expire after 12 hr so i can train model only for 12 hrs<br>\n",
    "4. need lot of cropped images<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
